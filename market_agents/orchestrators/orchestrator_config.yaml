# orchestrator_config.yaml

num_agents: 4
max_rounds: 1
environment_order:
  - group_chat
  - research
tool_mode: true
agent_config:
  knowledge_base: "nyc_business_kb"
  use_llm: true
llm_configs:
    - name: "gpt-4o"
      model: "gpt-4o"
      client: "openai"
      max_tokens: 4096
      temperature: 0.5
      use_cache: true
#    - name: "deepseek"
#      model: "deepseek-ai/DeepSeek-R1-Distill-Qwen-32B"
#      client: "litellm"
#      max_tokens: 4096
#      temperature: 0.5
#      use_cache: true
#    - name: "qwen"
#      model: "Qwen/QwQ-32B-Preview"
#      client: "vllm"
#      max_tokens: 4096
#      temperature: 0.5
#      use_cache: true
#    - name: "hermes"
#      model: "NousResearch/Hermes-3-Llama-3.1-8B"
#      client: "litellm"
#      max_tokens: 4096
#      temperature: 0.5
#      use_cache: true
#    - name: "qwen"
#      model: "Qwen/Qwen2.5-7B-Instruct"
#      client: "litellm"
#      max_tokens: 4096
#      temperature: 0.5
#      use_cache: true
#    - name: "internlm"
#      model: "internlm/internlm2_5-7b-chat"
#      client: "litellm"
#      max_tokens: 4096
#      temperature: 0.5
#      use_cache: true
#    - name: "mistral"
#      model: "mistralai/Mistral-7B-Instruct-v0.3"
#      client: "litellm"
#      max_tokens: 4096
#      temperature: 0.0
#      use_cache: true
#    - name: "llama"
#      model: "meta-llama/Llama-3.1-8B-Instruct"
#      client: "litellm"
#      max_tokens: 4096
#      temperature: 0.5
#      use_cache: true
#    - name: "functionary"
#      model: "meetkai/functionary-small-v3.1"
#      client: "litellm"
#      max_tokens: 4096
#      temperature: 0.5
#      use_cache: true
#    - name: "toolace"
#      model: "Team-ACE/ToolACE-8B"
#      client: "litellm"
#      max_tokens: 4096
#      temperature: 0.5
#      use_cache: true
#    - name: "minicpm"
#      model: "openbmb/MiniCPM3-4B"
#      client: "litellm"
#      max_tokens: 4096
#      temperature: 0.5
#      use_cache: true
environment_configs:
  group_chat:
    name: "group_chat"
    address: "http://localhost:8001"
    max_rounds: 5
  #  initial_topic: "Initial Market Discussion"
    initial_topic: "Estimate Starting a Business section scores for New York City (NYC) as part of doing business report"

    sub_rounds: 2
    group_size: 4
  research:
    name: "market_survey"
    address: "http://localhost:8002"
    max_rounds: 5
    initial_topic: "Estimate Starting a Business section scores for New York City (NYC) as part of doing business report"
    sub_rounds: 2
    group_size: 4
    schema_model: "StartingBusinessIndicators" 
protocol: "acl_message"
database_config:
  db_host: "localhost"
  db_port: "5433"